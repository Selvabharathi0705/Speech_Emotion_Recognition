# Speech_emotion_recognition
Built a LSTM model for emotion recognition also employed and tested a simple model which has layers.

Predicts the emotion of the audio file which is in a directory (local) 

### Description :

•⁠  ⁠<p align = "justify">Speech Emotion Recognition is the act of attempting to recognize human emotion and affective states from speech. This is capitalizing on the fact that voice often reflects underlying emotion through tone and pitch. This is a system which aims to predict the emotion of the speech using audio as its input.</p>

•⁠  ⁠<p align = "justify">This system is used in call centers for classifying calls according to emotions and can be used as the performance parameter for conversational analysis thus identifying the unsatisfied customer, customer satisfaction and so on for helping companies to improve services that they provide to the customers.</p>

### Requirements :

•⁠  ⁠Numpy
•⁠  ⁠Pandas
•⁠  ⁠Librosa
•⁠  ⁠Seaborn
•⁠  ⁠Matplotlib
•⁠  ⁠OS
•⁠  ⁠Glob
•⁠  ⁠Keras
•⁠  ⁠Scikit
•⁠  ⁠Audio

### Methodology :

•⁠  ⁠<p align = "justify">This system is built using the Long Short-Term Memory (LSTM) model and the Artificial Neural Network (ANN) model for emotion recognition on the audio that is given as the input. This system predicts the emotion of the audio files that are located in the local directory of the host machine.</p>

•⁠  ⁠<p align = "justify">The accuracy of the two models are increased by increasing the number of epochs that are given to the models. These models are trained on a set of known audio data and are used to predict the emotion of the unseen audio data that are given by the users.</p>


# dataset

https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess
